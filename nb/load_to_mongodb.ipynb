{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import OperationFailure\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import time\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Base Connection to mongodb://192.168.1.20:27017 Established........\n",
      "DBs available:\n",
      " DB Name: admin\n",
      "   Colections: ['system.version']\n",
      " DB Name: config\n",
      "   Colections: ['system.sessions']\n",
      " DB Name: local\n",
      "   Colections: ['startup_log']\n"
     ]
    }
   ],
   "source": [
    "def check_mongo_connection(client_uri):\n",
    "    connection = MongoClient(client_uri)\n",
    "\n",
    "    try:\n",
    "        connection.database_names\n",
    "        print('\\n')\n",
    "        print(f'Data Base Connection to {client_uri} Established........')\n",
    "        print('DBs available:')\n",
    "        for db_name in connection.list_databases():\n",
    "            print(' DB Name:', db_name['name'])\n",
    "            db = connection[db_name['name']]\n",
    "            collections =[]\n",
    "            for collection_name in db.list_collection_names():\n",
    "                collections.append(collection_name)\n",
    "            print('   Colections:', collections)\n",
    "          \n",
    "        \n",
    "    except OperationFailure as err:\n",
    "        print(f\"Data Base Connection failed. Error: {err}\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "client_uri = \"mongodb://192.168.1.20:27017\"\n",
    "server = check_mongo_connection(client_uri)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Dataset 1\n",
    "6. Turbofan Engine Degradation Simulation\n",
    "Engine degradation simulation was carried out using the Commercial Modular Aero-Propulsion System Simulation (C-MAPSS). Four different sets were simulated under different combinations of operational conditions and fault modes. This records several sensor channels to characterize fault evolution. The data set was provided by the NASA Ames Prognostics Center of Excellence (PCoE).\n",
    "\n",
    "https://data.nasa.gov/Aerospace/CMAPSS-Jet-Engine-Simulated-Data/ff5v-kuh6\n",
    "#### Read and Store Raw Data to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw files descriptions from website notes \n",
    "meta_data = [\n",
    "    {\n",
    "        'Data Set': 'FD001',\n",
    "        'Train trajectories': 100,\n",
    "        'Test trajectories': 100,\n",
    "        'Conditions': 'ONE (Sea Level)',\n",
    "        'Fault Modes': 'ONE (HPC Degradation)'\n",
    "    },\n",
    "    {\n",
    "        'Data Set': 'FD002',\n",
    "        'Train trajectories': 260,\n",
    "        'Test trajectories': 259,\n",
    "        'Conditions': 'SIX',\n",
    "        'Fault Modes': 'ONE (HPC Degradation)'\n",
    "    },\n",
    "    {\n",
    "        'Data Set': 'FD003',\n",
    "        'Train trajectories': 100,\n",
    "        'Test trajectories': 100,\n",
    "        'Conditions': 'ONE (Sea Level)',\n",
    "        'Fault Modes': 'TWO (HPC Degradation, Fan Degradation)'\n",
    "    },\n",
    "    {\n",
    "        'Data Set': 'FD004',\n",
    "        'Train trajectories': 248,\n",
    "        'Test trajectories': 249,\n",
    "        'Conditions': 'SIX',\n",
    "        'Fault Modes': 'TWO (HPC Degradation, Fan Degradation)'\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "column_names = [\n",
    "    'unit #', 'time (cycles)', 'op. setting 1', 'op. setting 2', 'op. setting 3',\n",
    "    'sensor 01', 'sensor 02', 'sensor 03', 'sensor 04', 'sensor 05',\n",
    "    'sensor 06', 'sensor 07', 'sensor 08', 'sensor 09', 'sensor 10',\n",
    "    'sensor 11', 'sensor 12', 'sensor 13', 'sensor 14', 'sensor 15',\n",
    "    'sensor 16', 'sensor 17', 'sensor 18', 'sensor 19', 'sensor 20', 'sensor 21',\n",
    "]\n",
    "\n",
    "data_sets = pd.DataFrame.from_records(meta_data)\n",
    "\n",
    "data_sets.set_index('Data Set', inplace = True)\n",
    "# data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train trajectories</th>\n",
       "      <th>Test trajectories</th>\n",
       "      <th>Conditions</th>\n",
       "      <th>Fault Modes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FD001</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>ONE (Sea Level)</td>\n",
       "      <td>ONE (HPC Degradation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD002</th>\n",
       "      <td>260</td>\n",
       "      <td>259</td>\n",
       "      <td>SIX</td>\n",
       "      <td>ONE (HPC Degradation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD003</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>ONE (Sea Level)</td>\n",
       "      <td>TWO (HPC Degradation, Fan Degradation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD004</th>\n",
       "      <td>248</td>\n",
       "      <td>249</td>\n",
       "      <td>SIX</td>\n",
       "      <td>TWO (HPC Degradation, Fan Degradation)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Train trajectories  Test trajectories       Conditions  \\\n",
       "Data Set                                                           \n",
       "FD001                    100                100  ONE (Sea Level)   \n",
       "FD002                    260                259              SIX   \n",
       "FD003                    100                100  ONE (Sea Level)   \n",
       "FD004                    248                249              SIX   \n",
       "\n",
       "                                     Fault Modes  \n",
       "Data Set                                          \n",
       "FD001                      ONE (HPC Degradation)  \n",
       "FD002                      ONE (HPC Degradation)  \n",
       "FD003     TWO (HPC Degradation, Fan Degradation)  \n",
       "FD004     TWO (HPC Degradation, Fan Degradation)  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read downloaded data and create DB tables (MongoDB Collections)\n",
    "def data_records(data_sets):\n",
    "\n",
    "    file_path = '/Volumes/share/Datasets/6_TurbofanEngineDegradationSimulationDataSet/CMAPSSData/'\n",
    "    file_prefixes = ['train', 'test']\n",
    "    column_groups = {}\n",
    "    database = server[db_set1]\n",
    "    for data_set, row in data_sets.iterrows():\n",
    "        columns = {}\n",
    "        for prefix in file_prefixes:\n",
    "            full_path = ''.join([file_path, prefix, '_', data_set,'.txt'])\n",
    "            df = pd.read_csv(full_path, sep=\" \")\n",
    "            df.dropna(axis=1, how='all', inplace=True)\n",
    "            df.columns = column_names\n",
    "\n",
    "            # Store dataset in the DB\n",
    "\n",
    "            colection = database[''.join([prefix, '_', data_set])]\n",
    "            new_data = colection.insert_many(df.to_dict('records'))\n",
    "        column_groups[data_set] = columns\n",
    "\n",
    "    return column_groups\n",
    "\n",
    "\n",
    "db_set1 = 'TurboFanDegradation_Set1'\n",
    "\n",
    "file_prefix = ['train', 'test']\n",
    "record_columns = data_records(data_sets)\n",
    "new_columns = pd.DataFrame.from_dict(record_columns,orient='index')\n",
    "\n",
    "data_sets = pd.concat([data_sets, new_columns], axis=1)\n",
    "data_sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "      <th>Documents (Tot. Records)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_FD001</td>\n",
       "      <td>26190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_FD002</td>\n",
       "      <td>67980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_FD003</td>\n",
       "      <td>16595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_FD004</td>\n",
       "      <td>41213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_FD001</td>\n",
       "      <td>41260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_FD002</td>\n",
       "      <td>107516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_FD003</td>\n",
       "      <td>24719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_FD004</td>\n",
       "      <td>61248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Collection  Documents (Tot. Records)\n",
       "0   test_FD001                     26190\n",
       "1   test_FD002                     67980\n",
       "2   test_FD003                     16595\n",
       "3   test_FD004                     41213\n",
       "4  train_FD001                     41260\n",
       "5  train_FD002                    107516\n",
       "6  train_FD003                     24719\n",
       "7  train_FD004                     61248"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the new created tables (Mongo DB collections)\n",
    "# list of strings\n",
    "collections = server[db_set1].list_collection_names()\n",
    "collections = sorted(collections)\n",
    "documents = []\n",
    "for collection in collections:\n",
    "    documents.append(server[db_set1][collection].estimated_document_count())\n",
    "   \n",
    "# Calling DataFrame constructor after zipping\n",
    "# both lists, with columns specified\n",
    "mongo_collections_df = pd.DataFrame(list(zip(collections, documents)),\n",
    "               columns =['Collection', 'Documents (Tot. Records)'])\n",
    "mongo_collections_df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Dataset 2\n",
    "17. Turbofan Engine Degradation Simulation-2\n",
    "The generation of data-driven prognostics models requires the availability of data sets with run-to-failure trajectories. To contribute to the development of these methods, the data set provides a new realistic data set of run-to-failure trajectories for a small fleet of aircraft engines under realistic flight conditions. The damage propagation modelling used for the generation of this synthetic data set builds on the modeling strategy from previous work. The data set was generated with the Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) dynamical model. The data set has been provided by the NASA Prognostics Center of Excellence (PCoE) in collaboration with ETH Zurich and PARC.\n",
    "\n",
    "https://phm-datasets.s3.amazonaws.com/NASA/17.+Turbofan+Engine+Degradation+Simulation+Data+Set+2.zip\n",
    "#### Read and Store Raw Data to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files are very large and scored in H5 format\n",
    "# The following function opends de files and \n",
    "def read_h5_file(filename):\n",
    "    # Time tracking, Operation time (min):  0.003\n",
    "    t = time.process_time()  \n",
    "\n",
    "    # Load data\n",
    "    with h5py.File(filename, 'r') as hdf:\n",
    "            # Development set\n",
    "            W_dev = np.array(hdf.get('W_dev'))             # W\n",
    "            X_s_dev = np.array(hdf.get('X_s_dev'))         # X_s\n",
    "            X_v_dev = np.array(hdf.get('X_v_dev'))         # X_v\n",
    "            T_dev = np.array(hdf.get('T_dev'))             # T\n",
    "            Y_dev = np.array(hdf.get('Y_dev'))             # RUL  \n",
    "            A_dev = np.array(hdf.get('A_dev'))             # Auxiliary\n",
    "\n",
    "            # Test set\n",
    "            W_test = np.array(hdf.get('W_test'))           # W\n",
    "            X_s_test = np.array(hdf.get('X_s_test'))       # X_s\n",
    "            X_v_test = np.array(hdf.get('X_v_test'))       # X_v\n",
    "            T_test = np.array(hdf.get('T_test'))           # T\n",
    "            Y_test = np.array(hdf.get('Y_test'))           # RUL  \n",
    "            A_test = np.array(hdf.get('A_test'))           # Auxiliary\n",
    "            \n",
    "            # Varnams\n",
    "            W_var = np.array(hdf.get('W_var'))\n",
    "            X_s_var = np.array(hdf.get('X_s_var'))  \n",
    "            X_v_var = np.array(hdf.get('X_v_var')) \n",
    "            T_var = np.array(hdf.get('T_var'))\n",
    "            A_var = np.array(hdf.get('A_var'))\n",
    "            \n",
    "            # from np.array to list dtype U4/U5\n",
    "            W_var = list(np.array(W_var, dtype='U20'))\n",
    "            X_s_var = list(np.array(X_s_var, dtype='U20'))  \n",
    "            X_v_var = list(np.array(X_v_var, dtype='U20')) \n",
    "            T_var = list(np.array(T_var, dtype='U20'))\n",
    "            A_var = list(np.array(A_var, dtype='U20'))\n",
    "                            \n",
    "    W = np.concatenate((W_dev, W_test), axis=0)  \n",
    "    X_s = np.concatenate((X_s_dev, X_s_test), axis=0)\n",
    "    X_v = np.concatenate((X_v_dev, X_v_test), axis=0)\n",
    "    T = np.concatenate((T_dev, T_test), axis=0)\n",
    "    Y = np.concatenate((Y_dev, Y_test), axis=0) \n",
    "    A = np.concatenate((A_dev, A_test), axis=0) \n",
    "        \n",
    "    print('')\n",
    "    print(\"Operation time (min): \" , (time.process_time()-t)/60)\n",
    "    print('')\n",
    "    print (\"W shape: \" + str(W.shape))\n",
    "    print (\"X_s shape: \" + str(X_s.shape))\n",
    "    print (\"X_v shape: \" + str(X_v.shape))\n",
    "    print (\"T shape: \" + str(T.shape))\n",
    "    print (\"A shape: \" + str(A.shape))\n",
    "\n",
    "    return A, A_var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e1df7214b896ba3d482856fa1b4374f6df405986cf6d589f47bd72fb1b9c3bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
